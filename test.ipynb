{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore some warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import numpy as np\n",
    "import jieba\n",
    "import ujson\n",
    "import pandas as pd\n",
    "from jieba import lcut\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from tools import flatten\n",
    "\n",
    "from tools import dereplication\n",
    "from tools import punctuation_line\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "# Set the log print content\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s:%(levelname)s: %(message)s', level=logging.INFO)\n",
    "jieba.setLogLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data file into memory\n",
    "def loaddata(filename, type='train'):\n",
    "    with open(filename, 'r', encoding='utf8') as file:\n",
    "        train_data = ujson.loads(file.read())\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "    documents = []\n",
    "    for _, value in train_data.items():\n",
    "        question = value['question']\n",
    "        for _, evidence in value['evidences'].items():\n",
    "            questions.append(question)\n",
    "            answer = ''.join(evidence['answer'])\n",
    "            answers.append(answer)\n",
    "            document = evidence['evidence']\n",
    "            documents.append(document)\n",
    "\n",
    "    train_simple = map(lambda x, y, z: [x, y, z], questions, answers, documents)\n",
    "\n",
    "    train_df = pd.DataFrame([item for item in train_simple], columns=['question', 'answer', 'document'])\n",
    "    print(train_df.describe())\n",
    "    train_df.to_csv('train' + '.csv', index=False, header=True)\n",
    "\n",
    "    return [questions, answers, documents, train_simple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPath:\n",
    "    def __init__(self):\n",
    "        self.train_data_path = 'data/me_train.json'\n",
    "        self.test_data_path = 'data/me_test.ann.json'\n",
    "        self.validation_data_path = 'data/me_validation.ann.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             question     answer                 document\ncount          448444     448444                   448444\nunique          36174      14910                   408410\ntop     南浦大桥于哪一年建成通车？  no_answer  1884年7月6日，自由女神像正式赠送给美国。\nfreq               29     307547                       25"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = DataPath()\n",
    "train_simples = loaddata(data_path.train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
